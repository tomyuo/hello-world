{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RDD Lab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "kvD4HBMi0ohY",
        "b4Kjvk_h1AHl",
        "Y_2Cd36sWuvN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomyuo/hello-world/blob/master/Kei_Ichikawa_RDD_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3T3_FYC4ZBBE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RDD Laboratory\n",
        "\n",
        "\n",
        "This an Individual work\n",
        "\n",
        "Exercise on unstructured data analysis on Spark. \n",
        "\n",
        "This work will be graded.\n"
      ]
    },
    {
      "metadata": {
        "id": "a4Jy9JGsPlcs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Instructions \n",
        "\n",
        "\n",
        "* This labs will be done at classroom. \n",
        "\n",
        "* When you finish the lab rename the notebook with your name. \n",
        "\n",
        "* Share it to me the notebook. My email is jgarciam@faculty.ie.edu\n",
        "\n",
        "\n",
        "\n",
        "**Objective**\n",
        "\n",
        "how do you understand the RDDs and how do you use them to solve issues\n",
        "\n",
        "** Questions ** \n",
        "\n",
        "The result of the lab must be have a little report about these 2 questions: \n",
        "\n",
        "Which are the most sold items (top 20)? \n",
        "\n",
        "Who are the users that buy the most (top 20)?\n",
        "\n",
        "** how am I going to evaluate this laboratory **\n",
        "\n",
        "* I value the way to solve the problem\n",
        "\n",
        "* Frequent comments that explain why something is being done\n",
        "\n",
        "* Is a plus if several alternatives are exposed and explain which is the best for you. \n",
        "\n",
        "\n",
        "** The Dataset **\n",
        "\n",
        "/content/SparkCourse2019/datasets/retail-data/all/online-retail-dataset.txt\n",
        "\n",
        "** The Dataset **\n",
        "\n",
        "github url: \n",
        "\n",
        "https://github.com/bazarum/SparkCourse2019/blob/master/datasets/retail-data/all/online-retail-dataset.txt\n",
        "\n",
        "spark path:\n",
        "\n",
        "/content/SparkCourse2019/datasets/retail-data/all/online-retail-dataset.txt\n",
        "\n",
        "\n",
        "The content of the file are sales.\n",
        "\n",
        "Fields are comma separated. \n",
        "\n",
        "The columns are: \n",
        "\n",
        " * InvoiceNo\n",
        " * StockCode\n",
        " * Description\n",
        " * Quantity\n",
        " * InvoiceDate\n",
        " * UnitPrice\n",
        " * CustomerID\n",
        " * Country\n",
        " \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kvD4HBMi0ohY"
      },
      "cell_type": "markdown",
      "source": [
        "## Spark Bootstraping for Google Colab\n",
        "\n",
        "Run this before start working with the notebooks from the spark course. \n",
        "When you will start a new (and fresh) notebook at Colab. Google Cloud will create a new Docker container just for your use. \n",
        "\n",
        "Executing this notebook will install into the container the software. The container will be reused by the user until it will destroy by inactivity.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fUhBhrGmyAvs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "b4Kjvk_h1AHl"
      },
      "cell_type": "markdown",
      "source": [
        "## Set Environment Variables\n",
        "Set the locations where Spark and Java are installed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8Xnb_ePUyQIL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[2] pyspark-shell\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y_2Cd36sWuvN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Cloning our Github repo"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PZkw_gPEQvId",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf /content/SparkCourse2019/\n",
        "!git clone https://github.com/bazarum/SparkCourse2019.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NwU28K5f1H3P"
      },
      "cell_type": "markdown",
      "source": [
        "## Start a SparkSession\n",
        "This will start a local Spark session."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zgReRGl0y23D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "print(findspark.init())\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "# from pyspark import SparkContext\n",
        "# sc = SparkContext(master = 'local[2]')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}